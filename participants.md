---
layout: page
title: "Workshop Presentations"
tags: [participants]
image:
  feature: pierce2.jpg
  credit: 
  creditlink: 
share: true
---
# DAAT (Jason Hockman & Joseph Thibodeau)

<figure>
	<a href="/images/daat.jpg"><img width="200" src="/images/daat.jpg" alt=""></a>
</figure>

DAAT is the collaboration of [Jason Hockman](http://www.music.mcgill.ca/~hockman/) and [Joseph Thibodeau](http://www.idmil.org/people/joseph_thibodeau). Their practice applies their musical and academic knowledge to the creation of immersive sound experiences. Often dark and machinistic, their music navigates the borderlands between soundstage and dancefloor.

Jason Hockman recently completed a PhD at McGill University in Music Technology focusing on the ethnographic and technological aspects of breakbeats in Hardcore, Jungle and Drum & Bass. His research includes automatic beat tracking and rhythmic analysis as well as qualitative surveys and interviews with renowned producers and label owners. 

Joseph Thibodeau is a musician and researcher associated with McGill University's Music Technology area and Concordia University's Penhune Laboratory for Motor Learning and Neural Plasticity. His work centres mainly around new digital musical instruments, specifically augmented trumpets, which he designs for use in live performance and studio production.

## Translating Visual Cues into the Auditory Domain

In this talk DAAT will discuss design choices and considerations for evoking visual imagery in the auditory domain within the context of 170 BPM dance music production. Topics discussed will include the historical, philosophical and practical usage of synthesis and sampling techniques in modern electronic dance music, and the parameterisation and manipulation of sampled sound.

# Carlos Dominguez

<figure>
	<a href="/images/dominguez.jpg"><img width="200" src="/images/dominguez.jpg" alt=""></a>
</figure>

[Carlos Dominguez](http://charlossound.wordpress.com/) works on a variety of different projects that involve chamber music, laptop performances, and sound installations. Most recently he has been interested in the uses of visible light in musical performances and compositions. He is currently a research assistant at Dartmouth College on a project with Jodie Mack.

## Light-Data Two Ways: Constructing Light Sensors for Analog and Digital Output
Carlos will give a tutorial on making a hybrid digital/analog device for reading visible light data and discuss how it can be used for installation and performance art. In collaboration with Alexander Dupuis, the device will be incorporated into a performance at the Workshop in the Woods.

# Alex Dupuis

<figure>
	<a href="/images/dupuis.png"><img width="200" src="/images/dupuis.png" alt=""></a>
</figure>

[Alex Dupuis](http://www.alexanderdupuis.com/about.php) is a composer, animator, and performer. His work investigates the intersections between experimental music and animation, focusing particularly on theories of audiovisual perception and transduction of information between light and sound. He performs as a guitarist, as well as with audiovisual instruments and software systems of his own design. He received an MA from Dartmouth's Digital Musics program in 2012, and is currently pursuing a PhD in Brown University's Multimedia & Electronic Music Experiments program.

## Digital raster scanning as audiovisual synthesis

The process of raster scanning, adapted from its analog television origins, offers a simple means of mapping between audio and video data. The flexibility afforded by this process allows for the creation of trans-modal feedback loops, as well as the application of effects from one domain to data originating in the other. Moreover, the distortions of the digital translation process can be exploited to create a wide array of new patterns, animations and sounds. Working in Max/MSP, I'll describe and implement an example of audiovisual raster scanning, discuss the considerations specific to a digital version, and demonstrate a number of the unique opportunities and by-products of the digital process.

# James Kerr

<figure>
	<a href="/images/kerr.jpg"><img width="200" src="/images/kerr.jpg" alt=""></a>
</figure>

James Kerr is an animator who creates GIFs using Renaissance art and graphic illustrations. His humorous work treats subjects such as religion, class, entertainment, and modernism by juxtaposing Renaissance art with graphic depictions drawn from pop cultural references. [His work](http://scorpiondagger.com/) has been featured on [Boing Boing](http://boingboing.net/2014/08/04/the-amazing-renaissance-art-gi.html) and other blogs.

## Animated GIFs, the Internet, and Art

It’s hard to escape the animated GIF. Spend anytime surfing the internet, and you are bound to see more than a few. From their use in marketing to internet memes, the GIF has seen a renaissance within the last few years. But despite their ubiquity, many are exploring the medium as art. In this workshop, James will explain his process of making an animated GIF by creating a collaborative piece with those in attendance, which he will post online at its completion. Who knows, maybe it go viral! 

# Le Révélateur (Roger Tellier-Craig & Sabrina Ratté)

<figure>
	<a href="/images/revelateur.jpg"><img width="200" src="/images/revelateur.jpg" alt=""></a>
</figure>

[Le Révélateur started](http://le-revelateur.tumblr.com/) in 2008 as a solo venture for Montreal-based 
electronic musician Roger Tellier-Craig. It has since then expanded 
into an audio-visual duo with the inclusion of video artist [Sabrina 
Ratté](http://sabrinaratte.com/) in 2010. Together they explore a common fascination for the 
combination of electronic image and sound, using a varying array of 
digital and analogue technologies. They have performed together at 
various festivals across North America and Europe, including On 
Land festival (San Francisco), Mutek (Montreal), Mutek.Mx (Mexico 
City), Electric Fields (Ottawa), Micro Mutek (Barcelona), Suoni per Il 
Popolo (Montreal), Send+Receive (Winnipeg) and Tone Deaf 
(Kingston). 

Le Révélateur has released recordings on Gneiss Things and NNA 
Tapes, as well as a new LP on Root Strata entitled “Extreme Events” 
in early September 2014. 

## Electronic Images and Sound

Sabrina anad Roger of Le Révélateur will discuss several aspects of their creative process, including the tools they use, inspirations, and relationships between images and music. Their talk will be accompanied by live performance and will conclude by kicking off Saturday night's AV Synth Jam.

# Jodie Mack

<figure>
	<a href="/images/mack.jpg"><img width="200" src="/images/mack.jpg" alt=""></a>
</figure>

[Jodie Mack](http://www.jodiemack.com/) is an experimental animator who received her MFA in film, video, and new media from The School of the Art Institute of Chicago in 2007 and currently teaches animation at Dartmouth College. Combining the formal techniques and structures of abstract/absolute animation with those of cinematic genres, her handmade films use collage to explore the relationship between graphic cinema and storytelling, the tension between form and meaning. Musical documentary or stroboscopic archive: her films study domestic and recycled materials to illuminate the elements shared between fine-art abstraction and mass-produced graphic design. Questioning the role of decoration in daily life, the works unleash the kinetic energy of overlooked and wasted objects.

## Description 
She will lead a demonstration of optical sound 16mm projector drum circles, share historical gems, and lead discussions on the contemporary possibilities and problems of A/V synthesis.

# Scott Petersen

<figure>
	<a href="/images/peterson.jpg"><img width="200" src="/images/peterson.jpg" alt=""></a>
</figure>

[Scott Petersen](http://scacinto.wordpress.com/bios/sca-c-i-n-t-o/) (aka s c a c i n t o | s k ɑ ʃ ɪ n t o ʊ | ) is a composer, performer, electronic musician
and laptop improviser. His current research and work revolves around open music technologies, improvisational electronic music, analog electronic instrument design, and experimental music programming. His output is diverse and includes works for large orchestra, small ensemble with and without electronics, works for large homogeneous instrumental groups, film/animation, sound installation, and laptop improvisation with custom designed hardware and software interfaces. Scott has performed and had his work performed and exhibited throughout the United States and Europe. He is a founding member of both the collaborative New Haven Electronic Music Composers group (El MuCo) and of [MakeHaven](http://makehaven.org/), a DIY maker space, and he founded and curates the FridayNightThing, an ongoing new music and arts gathering. Scott currently works as the Assistant Director of the [Yale Music Technology Labs](http://yalmust.yale.edu/) and as the director of the YalMusT Open Music Initiative in the Yale Department of Music.

## Systems and Methods of Performative Synthesis: Considerations for Improvising with Code

This workshop will provide the attendee with an introduction to several systems and methods for improvising with code, focussing specifically on the strengths and weaknesses of different approaches to live audio synthesis. The workshop will use the audio programming language SuperCollider for all examples, but the concepts are portable to other languages.

Key topics will include: data entry and interaction methods, communication protocols, language­specific goodies (UGens), one­liners, strengths and weaknesses of syntactic sugar, hardware considerations for real­time synthesis and more.

You may find it helpful to install SuperCollider before attending the workshop as example files, documentation and further reading will be provided beforehand.

# Andy Sarroff

<figure>
	<a href="/images/sarroff.jpg"><img width="200" src="/images/sarroff.jpg" alt=""></a>
</figure>

[Andy Sarroff](http://www.cs.dartmouth.edu/~sarroff/) is a doctoral student in Computer Science at Dartmouth working in the domain of music computation. He researches methods for data-driven musical audio synthesis using neural networks. Andy holds a Masters of Music from the Music Technology program at NYU and a BA in Music from Wesleyan University.

Past projects include prediction of spatial characteristics in recorded music; automatic playlist generation; operating system sonification; and extraction of rhythmic-acoustic descriptors for measuring musical groove similarity.

## Autoencoding Musical Synthesizers

Autoecoders are neural networks that learn to reproduce their input at their output. They have an encoding stage where an input data space is transformed into a hidden representation, and a decoding stage where the output of the hidden representation is transformed to the original data space. The first part of the talk will cover basic principles of autoencoders, including designing the model's structure, using activation functions, connectedness, training, and regularization. The second part of the talk will discuss the application of autoencoders for musical sound synthesis, including design challenges, musical interfaces, and performability.

# James Traer

<figure>
	<a href="/images/traer.jpg"><img width="200" src="/images/traer.jpg" alt=""></a>
</figure>

James Traer is a postdoctoral researcher at Josh McDermott's [Laboratory for Computational Audition](http://mcdermottlab.mit.edu/). He is a physicist and oceanographer whose prior work focused on extracting information from ambient noise in the ocean and Earth's crust. He is currently at MIT studying acoustic reverberation.

## Synthesis of realistic (and wildly unrealistic) sounding impulse responses from environmental statistics.

Every room is different and hence has a set of unique impulse responses associated with each possible source-listener orientation.  However, the percept of reverberation may be similar across a wide range of rooms and configurations therein.  This suggests that the perceptually important features of reverberation may be independent of the details of the fine-structure of the impulse response (determined by the exact configuration and properties of the room) and rather may depend more strongly on the bulk statistics of the impulse response time series (determined by features such as room size and average reflectance of all surfaces).  We have measured real-world impulse responses in over 200 real-world spaces, both indoor and outdoor, including rooms large and small.  We have measured the statistics of these impulse responses and by imposing these statistics on Gaussian random noise we can quickly and easily synthesize realistic sounding reverberation.  Moreover, if we set our synthesis algorithm to intentionally violate the statistics we have measured in the real-world, the resulting “reverberant” signal sounds noticeably synthetic and unnatural.  This implies that the human brain uses the statistics of real-world impulse responses to separate signal arriving at the ear into contributions from the sound source and echoes from environmental reverberation. 

# Kevin Woods

<figure>
	<a href="/images/woods.jpg"><img width="200" src="/images/woods.jpg" alt=""></a>
</figure>

Kevin Woods is a graduate student in the Speech and Hearing Bioscience and Technology program (Harvard-MIT) working under Josh McDermott at the MIT [Laboratory for Computational Audition](http://mcdermottlab.mit.edu/). His research interests include auditory attention and perceptual organization. 

## Principles of Auditory Scene Analysis for Audio Synthesis

Understanding the perceptual organization of sound can aid creative synthesis. For example, why might two different sounds fuse together rather than being heard as distinct? What kinds of sounds grab your attention, and why? Issues like these are not fully understood, but what we do know might help us better predict the perceptual effect of sounds we want to make, or guess how sounds should be changed to get the effects we want. In addition to primary processes which are largely obligatory, our perception of auditory scenes is also heavily influenced by attention. So, an awareness of attentional dynamics may also inform creative audio synthesis. Prior work tended to approach auditory attention as allocated in a stationary way to sound sources with consistent features. However, recent work suggests that attention can also track a sound source as it changes over time, and that this moving locus of attention can influence the formation of auditory objects and aid in selection among similar sources.

# Michael Casey

<figure>
	<a href="/images/casey.jpg"><img width="200" src="/images/casey.jpg" alt=""></a>
</figure>

[Michael Casey](http://eamusic.dartmouth.edu/~mcasey/) is an algorithm artist, electro-acoustic music composer, and computer scientist. His work explores the intersection of perception, cognition, creativity, algorithm, and culture. A co-editor of the MPEG-7 International Standard for Content-Based Media Archives, he applies algorithms to the creation of audio-visual art from film and sound archives. Michael has received international prizes and awards from the Bourges foundation (IMEB, Fr.), NEWCOMP (USA), Discover Awards, and funding from the National Endowment for the Humanities (NEH), Google Inc., Yahoo Inc., the Engineering and Physical Sciences Research Council (EPSRC, UK), Mellon Foundation / Leslie Center for the Humanities, and the Neukom Institute for Computational Science.

## Archive BLASTing for Audio-Visual Synthesis

I will present Dartmouth's BLAST (Bregman Labs' Audio-viSual Transformation) plugins for real-time retrieval from big media archives. BLAST tools are compatible with widely-used platforms via standard plug-in frameworks such as Max/MSP/Jitter, PD, VST, AU, and LADSPA. I will give examples of non-repeating dynamic texture synthesis and sonic control of archive-generated film, and speculate on the critical inter-mediation that these new computational tools afford.

# Spencer Topel

<figure>
	<a href="/images/topel.jpg"><img width="200" src="/images/topel.jpg" alt=""></a>
</figure>

[Spencer Topel](http://www.spencertopel.com/) is a composer and sound artist living in Hanover, NH. He holds a tenure-track position as an Assistant Professor of Music at Dartmouth College, and is involved with concerts and exhibitions throughout the United States and abroad. Upcoming events include work exhibited in the P.3+ in New Orleans and premieres in 2015 at Roulette in NYC and the NYU Skirball Center.

## Scaleable Art: Open Source for Sound Art and Installation

Over just the past five years, the Open-Source (OS) Hardware community has expanded into a multi-million dollar industry. The opportunities for integrating hardware/software OS have given rise to a new kind of inventor, but also provides opportunities for digital artists to explore previously costly or inaccessible projects, such as multi-computer installations, cluster computing for audio/video processing and sonification/visualization. This workshop will present the nuts and bolts of how to get started with OS Hardware/Software. 

# Daniel J Wilson

<figure>
	<a href="/images/wilson.jpg"><img width="200" src="/images/wilson.jpg" alt=""></a>
</figure>

[Daniel J Wilson](http://www.danieljwilson.com/) is an artist and filmmaker working across multiple media.  

His work has been exhibited at galleries and festivals internationally, including Bunkier Sztuki in Krakow, Broadway Media Center in Nottingham, The European Independent Film Festival in Paris, culturaDigital in Rio de Janeiro, the Copenhagen Art Festival, the DUMBO Arts Festival and MoMA PS1 in New York.  His work has been covered by The New York Times, The London Times, The Daily Telegraph, Neural, L Magazine and Art F City.

Wilson has recently completed residencies at SOMA in Mexico City, IMC Lab+Gallery in New York, a fellowship program with UnionDocs, and was selected to attend The School for Poetic Computation.  He is currently part of The New Museum’s incubator program NEW INC.  

His work has been supported by the Ontario Arts Council, the National Film Board of Canada, Grand NCE and the Canada Council for the Arts.

He was also a co-founder of the one year pop-up non-profit artspace MMX in Berlin in 2010 and works freelance as a co-producer and editor for the PBS FRONTLINE series.

Wilson holds a Bachelor of Arts & Science from McMaster University, and a MSc. in Art & Technology from the IT University at Chalmers in Göteborg, Sweden.

## HKL•••XYZ: Moving from reciprocal space to real space in X-ray crystallography

The workshop will be an introduction to the process of X-ray crystallography, widely used in structural biology (2014 is actually the UNESCO International Year of Crystallography), and an explanation of the process of molecular structure determination, which uses inverse Fourier transforms of information in reciprocal space to reveal real space information about the structure of a crystallized molecule.

The question of how to use the physical information about the crystals, both in reciprocal space as well as inverse Fourier transformed to real space, to create sonic representations of the molecule's structural information will be considered.

